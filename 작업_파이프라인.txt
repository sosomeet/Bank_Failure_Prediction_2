연구 파이프라인

1. 데이터 전처리 및 정규화
원시 재무지표 데이터를 대상으로 결측치 처리, 이상치 확인, 스케일 차이 보정을 수행한다.
모든 변수는 causal discovery 및 회귀 기반 분석이 가능하도록 정규화(z-score 또는 robust scaling)한다.
이 단계의 목적은 구조 학습 이전에 변수 간 비교 가능성을 확보하는 것이다.

2. 기초 분포 분석 (Raw Feature)
정규화된 재무지표의 분포를 시각화하여 정규성, 왜도, 극단값 여부를 확인한다.
이 분석은 이후 선형 가정(OLS, NOTEARS 등)의 한계를 해석하기 위한 기초 근거로 사용된다.

3. Causal Structure Learning (DAG 학습)
정규화된 데이터를 입력으로 다음 causal discovery 기법들을 적용한다.
 NOTEARS
 PC Algorithm
 GES
 GOLEM
각 기법은 재무지표 간의 방향성을 갖는 DAG를 출력하며, 이 DAG는 예측 모델이 아닌 구조적 관계 표현으로 사용된다.

4. DAG 비교 및 안정성 분석
서로 다른 기법에서 생성된 DAG를 비교하여 다음을 분석한다.
 edge 수 및 sparsity
 공통적으로 반복되는 edge
 bootstrap 기반 구조 안정성
 재무 도메인 관점에서의 방향성 타당성
이 단계의 목적은 “어떤 DAG가 맞는가”를 단정하는 것이 아니라, 일관되게 관측되는 구조적 관계가 존재하는지를 확인하는 것이다.

5. DAG 구조 고정
비교 결과를 바탕으로 분석에 사용할 DAG 구조를 선택하고 고정한다.
이후 단계에서는 DAG 구조를 변경하지 않으며, 모든 실험은 동일한 구조를 기준으로 수행한다.

6. DAG 기반 가중치 추정
고정된 DAG 구조 하에서 각 노드에 대해 부모 변수들을 사용한 회귀를 수행하여 가중치를 추정한다.
    X_j = f(Pa_j)+ε_j
여기서 f(⋅)는 선형(OLS) 또는 제한적 비선형 함수로 설정한다.
이 단계는 구조의 방향성을 수치화하는 과정이다.

7. DAG 기반 Feature 생성
DAG와 추정된 가중치를 이용하여 특정 노드의 parent-only feature 새로운 feature 표현을 생성한다.
이 단계의 핵심은 feature를 독립적인 입력이 아닌, 관계를 가진 표현으로 재구성하는 것이다.

8. DAG 기반 Feature 분포 분석
원래 feature 분포와 DAG 기반으로 생성된 feature 분포를 비교한다.
 분산 변화
 꼬리(tail) 구조 변화
 상관 구조 변화
이를 통해 구조적 관계를 반영했을 때 데이터 표현이 어떻게 달라지는지를 분석한다.

9. 예측 모델 학습
동일한 예측 모델을 사용하여 다음 세 가지 설정을 비교한다.
 원본 feature만 사용
 DAG 기반 feature만 사용
 원본 + DAG 기반 feature 결합

사용 모델은 다음과 같다.
 Logit
 RF
 LightGBM
 XGBoost
 TabNet
이 단계에서의 비교는 모델이 아니라 feature 표현의 차이에 초점을 둔다.

10. 설명(XAI) 비교 분석
예측 결과에 대해 다음 두 가지 설명 방식을 비교한다.
기존 방식: SHAP, permutation importance
DAG 기반 방식: 부모–자식 관계 중심 구조적 설명
설명의 일관성, 안정성, 도메인 해석 가능성을 정성·정량적으로 비교한다.

11. 구조 무작위화 검정 (Sanity Check)
DAG의 구조적 의미를 검증하기 위해 다음 무작위 실험을 수행한다.
 edge 무작위 섞기
 가중치 무작위 permutation
원래 DAG와 무작위 DAG를 비교하여 예측 및 설명 결과의 차이를 분석한다.
이 단계는 “DAG의 구조 자체가 의미 있는가”를 검증하는 핵심 실험이다.

12. 개입 및 반사실 분석
고정된 DAG를 Structural Causal Model(SCM)로 해석하여 제한적인 개입 시뮬레이션을 수행한다.
 특정 재무지표를 변화시켰다고 가정했을 때 failure 확률 변화
 실패 사례에 대한 counterfactual 설명
이는 정책 제안이 아닌 구조적 해석 보조 수단으로 활용한다.