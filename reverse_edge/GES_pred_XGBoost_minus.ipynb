{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c222efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q causal-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# causal-learn: 정확한 GES 구현\n",
    "from causallearn.search.ScoreBased.GES import ges   # 기본 점수는 BIC\n",
    "# from causallearn.score.LocalScoreFunction import local_score_BIC\n",
    "\n",
    "# 한글 폰트/마이너스 설정(선택)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 0) 데이터 로드 (기존과 동일)\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "feature_cols = df.drop(columns=[\"Unnamed: 0\", \"label\"]).columns\n",
    "X_base = df[feature_cols].copy()\n",
    "y = df[\"label\"].astype(int)\n",
    "cols_for_w = list(feature_cols)\n",
    "cols = cols_for_w  # 시각화 라벨 호환\n",
    "\n",
    "# 1) 정확한 GES 실행 (기본 BIC 점수 사용)\n",
    "X_np = X_base.values.astype(float)\n",
    "Record = ges(X_np)  # 또는 Record = ges(X_np, score_func='local_score_BIC')\n",
    "Gmat = Record['G'].graph  # orientation 행렬 (numpy.ndarray)\n",
    "# 문서: G.graph[j,i]=1 & G.graph[i,j]=-1 이면 i -> j (i가 부모, j가 자식)\n",
    "\n",
    "# 2) 방향성 인접행렬 A (i <- j 형태로 저장하기 위해 A[child, parent]=1)\n",
    "p = len(cols_for_w)\n",
    "A = np.zeros((p, p), dtype=float)\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        if i == j:\n",
    "            continue\n",
    "        # i -> j ?\n",
    "        if (Gmat[j, i] == 1) and (Gmat[i, j] == -1):\n",
    "            A[j, i] = 1.0  # child=j, parent=i\n",
    "\n",
    "# 3) 표준화 OLS로 엣지 가중치 행렬 W (i <- j)\n",
    "Z = StandardScaler().fit_transform(X_np)\n",
    "W = np.zeros_like(A, dtype=float)\n",
    "for child in range(p):\n",
    "    parents = np.where(A[child, :] == 1.0)[0]\n",
    "    if parents.size == 0:\n",
    "        continue\n",
    "    y_child = Z[:, child]\n",
    "    X_par = Z[:, parents]\n",
    "    coef, *_ = np.linalg.lstsq(X_par, y_child, rcond=None)  # 절편 없음(표준화)\n",
    "    W[child, parents] = coef.astype(float)\n",
    "\n",
    "# ============ 여기부터 시각화 개선(음수 가중치 지원) ============\n",
    "\n",
    "# 시각화 임계 설정\n",
    "USE_QUANTILE = False      # 분위수 임계 사용 여부\n",
    "W_THRESHOLD = 0.01        # 고정 임계(|W|>0.01)\n",
    "W_ABS_QUANTILE = 0.90     # 상위 10%만 (USE_QUANTILE=True일 때 사용)\n",
    "\n",
    "TOP_K_EDGES = None        # 상위 |w| 간선만 표시하고 싶으면 정수(예: 100)로 설정\n",
    "\n",
    "def get_threshold(W, fixed=W_THRESHOLD, use_q=USE_QUANTILE, q=W_ABS_QUANTILE):\n",
    "    if not use_q:\n",
    "        return fixed\n",
    "    aw = np.abs(W).ravel()\n",
    "    aw = aw[aw > 0]\n",
    "    return float(np.quantile(aw, q)) if aw.size else fixed\n",
    "\n",
    "thr = get_threshold(W)\n",
    "\n",
    "# 4) 임계 적용 + (선택) 상위 K개 필터 → DiGraph 구성\n",
    "edges_all = []\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        if i == j:\n",
    "            continue\n",
    "        w = float(W[i, j])\n",
    "        if abs(w) > thr:\n",
    "            edges_all.append((cols[j], cols[i], w))  # parent -> child, weight=w\n",
    "\n",
    "# 상위 K개만 표시(선택)\n",
    "if TOP_K_EDGES is not None and TOP_K_EDGES > 0 and len(edges_all) > TOP_K_EDGES:\n",
    "    edges_all = sorted(edges_all, key=lambda t: abs(t[2]), reverse=True)[:TOP_K_EDGES]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for u, v, w in edges_all:\n",
    "    G.add_edge(u, v, weight=round(w, 3))\n",
    "\n",
    "# ---- 배치: 음수 가중치 문제 해결 (거리=1/(|w|+ε)로 양의 거리 그래프 H 구성)\n",
    "eps = 1e-6\n",
    "H = nx.Graph()  # 레이아웃 전용 보조 그래프(무향 + 양의 거리)\n",
    "for u, v, d in G.edges(data=True):\n",
    "    w = d.get(\"weight\", 0.0)\n",
    "    dist = 1.0 / (abs(w) + eps)   # |w| 클수록 더 가까워지도록\n",
    "    H.add_edge(u, v, weight=dist)\n",
    "\n",
    "pos = nx.kamada_kawai_layout(H, weight='weight')  # 안정적 배치\n",
    "\n",
    "# ---- 스타일: 부호/크기 시각화\n",
    "max_abs = max((abs(d[\"weight\"]) for _, _, d in G.edges(data=True)), default=1.0)\n",
    "pos_edges = [(u, v) for u, v, d in G.edges(data=True) if d[\"weight\"] >= 0]\n",
    "neg_edges = [(u, v) for u, v, d in G.edges(data=True) if d[\"weight\"] < 0]\n",
    "pos_widths = [1.0 + 3.0 * abs(G[u][v][\"weight\"]) / max_abs for u, v in pos_edges]\n",
    "neg_widths = [1.0 + 3.0 * abs(G[u][v][\"weight\"]) / max_abs for u, v in neg_edges]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw_networkx_nodes(G, pos, node_size=2000, node_color=\"white\", edgecolors=\"black\")\n",
    "nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "# 양수: 파란 실선 / 음수: 빨간 점선\n",
    "nx.draw_networkx_edges(G, pos, edgelist=pos_edges, edge_color=\"tab:blue\", width=pos_widths, arrows=True)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=neg_edges, edge_color=\"tab:red\",  width=neg_widths, style=\"dashed\", arrows=True)\n",
    "\n",
    "# 원래 가중치 라벨(부호 유지)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'weight'), font_size=8)\n",
    "plt.title(\"정확한 GES 기반 인과 그래프 (배치=|w| 거리, 색/스타일=부호, 굵기=|w|)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e1e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.24773927  0.          0.01658714  0.         -1.0510666   0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.12171732]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.14418336  0.          0.13943481  0.          0.          0.\n",
      "   0.         -0.05994442  0.          0.13125204  0.          0.\n",
      "   0.43965624]\n",
      " [ 0.70701973  0.          0.11274439  0.          0.          0.\n",
      "  -0.03061962  0.03198602  0.          0.          0.          0.\n",
      "  -0.33246915]\n",
      " [-0.09667648 -0.16348889  0.          0.         -0.32695599  0.\n",
      "   0.17001459  0.98201021 -0.36097817  0.59948669  0.          0.\n",
      "   0.        ]\n",
      " [-0.16704123  0.          0.40835233  0.40847392  0.          0.\n",
      "   0.          0.          0.         -0.09262878  0.          0.\n",
      "   0.18446669]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.26180978  0.          0.          0.18705251 -0.12629701\n",
      "   0.          0.          0.04243416 -0.09443385  0.          0.\n",
      "   0.0559971 ]\n",
      " [ 0.          0.          0.10323437  0.          0.          0.34833146\n",
      "  -0.1730576   0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [-0.24773927, -0.        , -0.01658714, -0.        ,  1.0510666 ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.12171732],\n",
       "       [-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [-0.14418336, -0.        , -0.13943481, -0.        , -0.        ,\n",
       "        -0.        , -0.        ,  0.05994442, -0.        , -0.13125204,\n",
       "        -0.        , -0.        , -0.43965624],\n",
       "       [-0.70701973, -0.        , -0.11274439, -0.        , -0.        ,\n",
       "        -0.        ,  0.03061962, -0.03198602, -0.        , -0.        ,\n",
       "        -0.        , -0.        ,  0.33246915],\n",
       "       [ 0.09667648,  0.16348889, -0.        , -0.        ,  0.32695599,\n",
       "        -0.        , -0.17001459, -0.98201021,  0.36097817, -0.59948669,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [ 0.16704123, -0.        , -0.40835233, -0.40847392, -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        ,  0.09262878,\n",
       "        -0.        , -0.        , -0.18446669],\n",
       "       [-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.26180978, -0.        , -0.        , -0.18705251,\n",
       "         0.12629701, -0.        , -0.        , -0.04243416,  0.09443385,\n",
       "        -0.        , -0.        , -0.0559971 ],\n",
       "       [-0.        , -0.        , -0.10323437, -0.        , -0.        ,\n",
       "        -0.34833146,  0.1730576 , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ],\n",
       "       [-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(W)\n",
    "W = W*-1\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71e0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O(original)] fold 1/10 ...\n",
      "[O(original)] fold 2/10 ...\n",
      "[O(original)] fold 3/10 ...\n",
      "[O(original)] fold 4/10 ...\n",
      "[O(original)] fold 5/10 ...\n",
      "[O(original)] fold 6/10 ...\n",
      "[O(original)] fold 7/10 ...\n",
      "[O(original)] fold 8/10 ...\n",
      "[O(original)] fold 9/10 ...\n",
      "[O(original)] fold 10/10 ...\n",
      "[F(m)] fold 1/10 ...\n",
      "[F(m)] fold 2/10 ...\n",
      "[F(m)] fold 3/10 ...\n",
      "[F(m)] fold 4/10 ...\n",
      "[F(m)] fold 5/10 ...\n",
      "[F(m)] fold 6/10 ...\n",
      "[F(m)] fold 7/10 ...\n",
      "[F(m)] fold 8/10 ...\n",
      "[F(m)] fold 9/10 ...\n",
      "[F(m)] fold 10/10 ...\n",
      "[OF(m)] fold 1/10 ...\n",
      "[OF(m)] fold 2/10 ...\n",
      "[OF(m)] fold 3/10 ...\n",
      "[OF(m)] fold 4/10 ...\n",
      "[OF(m)] fold 5/10 ...\n",
      "[OF(m)] fold 6/10 ...\n",
      "[OF(m)] fold 7/10 ...\n",
      "[OF(m)] fold 8/10 ...\n",
      "[OF(m)] fold 9/10 ...\n",
      "[OF(m)] fold 10/10 ...\n",
      "[F(mw)] fold 1/10 ...\n",
      "[F(mw)] fold 2/10 ...\n",
      "[F(mw)] fold 3/10 ...\n",
      "[F(mw)] fold 4/10 ...\n",
      "[F(mw)] fold 5/10 ...\n",
      "[F(mw)] fold 6/10 ...\n",
      "[F(mw)] fold 7/10 ...\n",
      "[F(mw)] fold 8/10 ...\n",
      "[F(mw)] fold 9/10 ...\n",
      "[F(mw)] fold 10/10 ...\n",
      "[OF(mw)] fold 1/10 ...\n",
      "[OF(mw)] fold 2/10 ...\n",
      "[OF(mw)] fold 3/10 ...\n",
      "[OF(mw)] fold 4/10 ...\n",
      "[OF(mw)] fold 5/10 ...\n",
      "[OF(mw)] fold 6/10 ...\n",
      "[OF(mw)] fold 7/10 ...\n",
      "[OF(mw)] fold 8/10 ...\n",
      "[OF(mw)] fold 9/10 ...\n",
      "[OF(mw)] fold 10/10 ...\n",
      "[F(m+mw)] fold 1/10 ...\n",
      "[F(m+mw)] fold 2/10 ...\n",
      "[F(m+mw)] fold 3/10 ...\n",
      "[F(m+mw)] fold 4/10 ...\n",
      "[F(m+mw)] fold 5/10 ...\n",
      "[F(m+mw)] fold 6/10 ...\n",
      "[F(m+mw)] fold 7/10 ...\n",
      "[F(m+mw)] fold 8/10 ...\n",
      "[F(m+mw)] fold 9/10 ...\n",
      "[F(m+mw)] fold 10/10 ...\n",
      "[OF(m+mw)] fold 1/10 ...\n",
      "[OF(m+mw)] fold 2/10 ...\n",
      "[OF(m+mw)] fold 3/10 ...\n",
      "[OF(m+mw)] fold 4/10 ...\n",
      "[OF(m+mw)] fold 5/10 ...\n",
      "[OF(m+mw)] fold 6/10 ...\n",
      "[OF(m+mw)] fold 7/10 ...\n",
      "[OF(m+mw)] fold 8/10 ...\n",
      "[OF(m+mw)] fold 9/10 ...\n",
      "[OF(m+mw)] fold 10/10 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">O</th>\n",
       "      <th colspan=\"5\" halign=\"left\">F</th>\n",
       "      <th colspan=\"5\" halign=\"left\">OF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>ECE</th>\n",
       "      <th>f1</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>ECE</th>\n",
       "      <th>f1</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>ECE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.3551</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.3551</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.4702</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mw</th>\n",
       "      <td>0.3551</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.3974</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m+mw</th>\n",
       "      <td>0.3551</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.3989</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               O                                       F                 \\\n",
       "              f1   AUPRC   AUROC   Brier     ECE      f1   AUPRC  AUROC   \n",
       "original  0.3551  0.4408  0.9097  0.0593  0.1455     NaN     NaN    NaN   \n",
       "m         0.3551  0.4408  0.9097  0.0593  0.1455  0.3793  0.4670  0.916   \n",
       "mw        0.3551  0.4408  0.9097  0.0593  0.1455  0.3835  0.4602  0.915   \n",
       "m+mw      0.3551  0.4408  0.9097  0.0593  0.1455  0.3900  0.4592  0.917   \n",
       "\n",
       "                              OF                                  \n",
       "           Brier     ECE      f1   AUPRC   AUROC   Brier     ECE  \n",
       "original     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "m         0.0410  0.0926  0.3774  0.4702  0.9201  0.0455  0.1196  \n",
       "mw        0.0369  0.0798  0.3974  0.4855  0.9225  0.0413  0.1012  \n",
       "m+mw      0.0353  0.0733  0.3989  0.4775  0.9218  0.0398  0.0956  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# GES → Top-15 → mul/mulw → XGBoost (xgb.train) → O/F/OF\n",
    "# 10-fold CV, O는 1회만 → 총 70회 학습\n",
    "# 결과: 행[original, m, mw, m+mw] × 열[O,F,OF × f1,AUPRC,AUROC,Brier,ECE]\n",
    "# (버전 호환: early_stopping_rounds + predict iteration_range/ntree_limit 자동 처리)\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, brier_score_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from causallearn.search.ScoreBased.GES import ges\n",
    "\n",
    "# ---------------- 설정 ----------------\n",
    "DATA_PATH = \"./training_data.csv\"\n",
    "LABEL_COL = \"label\"\n",
    "ID_PREFIX = \"Unnamed\"\n",
    "\n",
    "TOP_K_EDGES   = 15\n",
    "N_SPLITS      = 10\n",
    "RANDOM_STATE  = 42\n",
    "PRINT_PROGRESS = True\n",
    "\n",
    "# XGBoost (xgb.train용) 기본 파라미터\n",
    "XGB_PARAMS_BASE = dict(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    eta=0.05,              # learning_rate\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    alpha=0.0,             # reg_alpha\n",
    "    lambda_=1.0,           # reg_lambda (키 이름은 아래 변환 함수에서 처리)\n",
    "    min_child_weight=1.0,\n",
    "    tree_method=\"hist\",\n",
    "    nthread=-1,\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "NUM_BOOST_ROUND = 400\n",
    "EARLY_STOPPING  = 50\n",
    "# -------------------------------------\n",
    "\n",
    "\n",
    "# 1) 데이터 로드\n",
    "path = Path(DATA_PATH)\n",
    "assert path.exists(), f\"파일을 찾을 수 없습니다: {path}\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "assert LABEL_COL in df.columns, f\"'{LABEL_COL}' 컬럼이 없습니다.\"\n",
    "id_cols = [c for c in df.columns if c.startswith(ID_PREFIX)]\n",
    "feature_cols = [c for c in df.columns if c not in id_cols + [LABEL_COL]]\n",
    "\n",
    "X_base = df[feature_cols].copy()\n",
    "y = df[LABEL_COL].astype(int).copy()\n",
    "\n",
    "# 2) GES → 표준화 OLS로 W(부호 포함) 계산\n",
    "var0_cols = [c for c in feature_cols if np.isclose(X_base[c].var(ddof=0), 0.0)]\n",
    "cols_used = [c for c in feature_cols if c not in var0_cols]\n",
    "X_np_full = X_base[cols_used].values.astype(float)\n",
    "\n",
    "Record = ges(X_np_full)                    # 기본 BIC\n",
    "Gmat = Record['G'].graph                   # G.graph[j,i]=1 & G.graph[i,j]=-1 → i -> j\n",
    "\n",
    "p = len(cols_used)\n",
    "A = np.zeros((p, p), dtype=float)\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        if i == j: \n",
    "            continue\n",
    "        if (Gmat[j, i] == 1) and (Gmat[i, j] == -1):  # i -> j\n",
    "            A[j, i] = 1.0  # child=j, parent=i\n",
    "\n",
    "Z = StandardScaler().fit_transform(X_np_full)\n",
    "W_used = np.zeros_like(A, dtype=float)\n",
    "for child in range(p):\n",
    "    parents = np.where(A[child, :] == 1.0)[0]\n",
    "    if parents.size == 0:\n",
    "        continue\n",
    "    y_child = Z[:, child]\n",
    "    X_par = Z[:, parents]\n",
    "    coef, *_ = np.linalg.lstsq(X_par, y_child, rcond=None)\n",
    "    W_used[child, parents] = coef.astype(float)\n",
    "\n",
    "\n",
    "# === 유틸 ===\n",
    "def pick_top_k_edges(W: np.ndarray, cols: List[str], top_k: int = 15):\n",
    "    \"\"\"(i <- j, weight=W[i,j]) 기준 상위 |w| 간선 선택 → [(i, j, w_ij), ...]\"\"\"\n",
    "    n = W.shape[0]\n",
    "    flat = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            w = W[i, j]\n",
    "            if w == 0.0:\n",
    "                continue\n",
    "            flat.append((i, j, w))\n",
    "    flat.sort(key=lambda t: (abs(t[2]), t[2]), reverse=True)\n",
    "    return flat[:top_k]\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, n_bins: int = 10):\n",
    "    y_true = np.asarray(y_true); y_prob = np.asarray(y_prob)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0; total = len(y_true)\n",
    "    for b in range(n_bins):\n",
    "        left, right = bins[b], bins[b+1]\n",
    "        mask = (y_prob >= left) & (y_prob < right) if b < n_bins-1 else (y_prob >= left) & (y_prob <= right)\n",
    "        if not np.any(mask): \n",
    "            continue\n",
    "        acc = y_true[mask].mean()\n",
    "        conf = y_prob[mask].mean()\n",
    "        ece += (mask.sum()/total) * abs(acc-conf)\n",
    "    return float(ece)\n",
    "\n",
    "def build_feature_df(X_base: pd.DataFrame, cols: List[str], W: np.ndarray, feature_type: str = \"mul\", top_k: int = 15):\n",
    "    \"\"\"feature_type ∈ {\"mul\",\"mulw\"}  /  w_ij = W[i,j], A=cols[j](parent), B=cols[i](child)\"\"\"\n",
    "    edges = pick_top_k_edges(W, cols, top_k=top_k)\n",
    "    feats = {}\n",
    "    for i, j, w_ij in edges:\n",
    "        A_name, B_name = cols[j], cols[i]\n",
    "        if feature_type == \"mul\":\n",
    "            feats[f\"{A_name}_mul_{B_name}\"] = X_base[A_name] * X_base[B_name]\n",
    "        elif feature_type == \"mulw\":\n",
    "            feats[f\"{A_name}_mulw_{B_name}\"] = w_ij * (X_base[A_name] * X_base[B_name])\n",
    "        else:\n",
    "            raise ValueError(\"feature_type must be 'mul' or 'mulw'\")\n",
    "    return pd.DataFrame(feats, index=X_base.index)\n",
    "\n",
    "def scale_pos_weight_from_labels(y_arr: np.ndarray) -> float:\n",
    "    pos = (y_arr == 1).sum()\n",
    "    neg = (y_arr == 0).sum()\n",
    "    return float(neg / max(pos, 1))\n",
    "\n",
    "def _params_for_train(base: Dict, spw: float, seed: int) -> Dict:\n",
    "    \"\"\"XGB train용 파라미터 정리 (lambda 키 호환 처리)\"\"\"\n",
    "    params = {\n",
    "        \"objective\": base.get(\"objective\", \"binary:logistic\"),\n",
    "        \"eval_metric\": base.get(\"eval_metric\", \"auc\"),\n",
    "        \"eta\": base.get(\"eta\", 0.05),\n",
    "        \"max_depth\": base.get(\"max_depth\", 6),\n",
    "        \"subsample\": base.get(\"subsample\", 0.8),\n",
    "        \"colsample_bytree\": base.get(\"colsample_bytree\", 0.8),\n",
    "        \"alpha\": base.get(\"alpha\", 0.0),\n",
    "        \"min_child_weight\": base.get(\"min_child_weight\", 1.0),\n",
    "        \"tree_method\": base.get(\"tree_method\", \"hist\"),\n",
    "        \"nthread\": base.get(\"nthread\", -1),\n",
    "        \"seed\": seed,\n",
    "        \"scale_pos_weight\": spw,\n",
    "    }\n",
    "    # lambda 키 호환\n",
    "    if \"lambda\" in base:\n",
    "        params[\"lambda\"] = base[\"lambda\"]\n",
    "    elif \"lambda_\" in base:\n",
    "        params[\"lambda\"] = base[\"lambda_\"]\n",
    "    else:\n",
    "        params[\"lambda\"] = 1.0\n",
    "    return params\n",
    "\n",
    "def _predict_booster(bst: xgb.Booster, dtest: xgb.DMatrix, default_rounds: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    XGBoost 버전에 따라:\n",
    "    - 선호: iteration_range=(0, best_iteration+1)\n",
    "    - 실패 시: ntree_limit=best_iteration+1\n",
    "    - 둘 다 실패 시: 기본 predict()\n",
    "    \"\"\"\n",
    "    end = getattr(bst, \"best_iteration\", None)\n",
    "    end = (int(end) + 1) if (end is not None and end >= 0) else default_rounds\n",
    "    # 1) iteration_range (신규)\n",
    "    try:\n",
    "        return bst.predict(dtest, iteration_range=(0, end))\n",
    "    except TypeError:\n",
    "        pass\n",
    "    # 2) ntree_limit (구버전)\n",
    "    try:\n",
    "        return bst.predict(dtest, ntree_limit=end)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    # 3) fallback\n",
    "    return bst.predict(dtest)\n",
    "\n",
    "# === XGBoost 교차검증 ===\n",
    "def run_cv_xgb(X: pd.DataFrame, y: pd.Series, n_splits=10, random_state=42, tag: str = \"\") -> Dict[str, float]:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    f1s, auprcs, aurocs, briers, eces = [], [], [], [], []\n",
    "\n",
    "    X_np = X.values.astype(np.float32)\n",
    "    y_np = y.values.astype(int)\n",
    "\n",
    "    for fold, (tr_idx, te_idx) in enumerate(skf.split(X_np, y_np), start=1):\n",
    "        if PRINT_PROGRESS and tag:\n",
    "            print(f\"[{tag}] fold {fold}/{n_splits} ...\", flush=True)\n",
    "\n",
    "        X_tr, X_te = X_np[tr_idx], X_np[te_idx]\n",
    "        y_tr, y_te = y_np[tr_idx], y_np[te_idx]\n",
    "\n",
    "        # 내부 검증(조기 종료)\n",
    "        X_tr_sub, X_val, y_tr_sub, y_val = train_test_split(\n",
    "            X_tr, y_tr, test_size=0.2, random_state=random_state, stratify=y_tr\n",
    "        )\n",
    "\n",
    "        spw = scale_pos_weight_from_labels(y_tr_sub)\n",
    "        params = _params_for_train(XGB_PARAMS_BASE, spw, seed=random_state)\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr_sub, label=y_tr_sub)\n",
    "        dval   = xgb.DMatrix(X_val,    label=y_val)\n",
    "        dtest  = xgb.DMatrix(X_te,     label=y_te)\n",
    "\n",
    "        evals = [(dval, \"eval\")]\n",
    "        bst = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=NUM_BOOST_ROUND,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=EARLY_STOPPING,\n",
    "            maximize=True,           # AUC 최대화\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        y_proba = _predict_booster(bst, dtest, default_rounds=NUM_BOOST_ROUND)\n",
    "        y_pred  = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "        f1s.append(f1_score(y_te, y_pred, zero_division=0))\n",
    "        try:\n",
    "            aurocs.append(roc_auc_score(y_te, y_proba))\n",
    "        except Exception:\n",
    "            aurocs.append(np.nan)\n",
    "        try:\n",
    "            auprcs.append(average_precision_score(y_te, y_proba))\n",
    "        except Exception:\n",
    "            auprcs.append(np.nan)\n",
    "        briers.append(brier_score_loss(y_te, y_proba))\n",
    "        eces.append(expected_calibration_error(y_te, y_proba, n_bins=10))\n",
    "\n",
    "    return {\n",
    "        \"f1\": float(np.nanmean(f1s)),\n",
    "        \"AUPRC\": float(np.nanmean(auprcs)),\n",
    "        \"AUROC\": float(np.nanmean(aurocs)),\n",
    "        \"Brier\": float(np.nanmean(briers)),\n",
    "        \"ECE\": float(np.nanmean(eces)),\n",
    "    }\n",
    "\n",
    "\n",
    "# 3) 파생 피처 생성 (GES-W 기반)\n",
    "Xf_m   = build_feature_df(X_base[cols_used], cols_used, W_used, feature_type=\"mul\",  top_k=TOP_K_EDGES)\n",
    "Xf_mw  = build_feature_df(X_base[cols_used], cols_used, W_used, feature_type=\"mulw\", top_k=TOP_K_EDGES)\n",
    "Xf_mmw = pd.concat([Xf_m, Xf_mw], axis=1)\n",
    "\n",
    "# 4) 평가 (O는 1회만 학습 → 재사용)\n",
    "res_O      = run_cv_xgb(X_base, y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"O(original)\")\n",
    "res_F_m    = run_cv_xgb(Xf_m,  y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"F(m)\")\n",
    "res_OF_m   = run_cv_xgb(pd.concat([X_base, Xf_m], axis=1),  y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"OF(m)\")\n",
    "\n",
    "res_F_mw   = run_cv_xgb(Xf_mw, y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"F(mw)\")\n",
    "res_OF_mw  = run_cv_xgb(pd.concat([X_base, Xf_mw], axis=1), y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"OF(mw)\")\n",
    "\n",
    "res_F_mmw  = run_cv_xgb(Xf_mmw, y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"F(m+mw)\")\n",
    "res_OF_mmw = run_cv_xgb(pd.concat([X_base, Xf_mmw], axis=1), y, n_splits=N_SPLITS, random_state=RANDOM_STATE, tag=\"OF(m+mw)\")\n",
    "\n",
    "# 5) 결과 표 구성 (저장 스니펫과 호환)\n",
    "col_top = [\"O\", \"F\", \"OF\"]\n",
    "col_metrics = [\"f1\", \"AUPRC\", \"AUROC\", \"Brier\", \"ECE\"]\n",
    "multi_cols = pd.MultiIndex.from_product([col_top, col_metrics])\n",
    "index_rows = [\"original\", \"m\", \"mw\", \"m+mw\"]\n",
    "\n",
    "report = pd.DataFrame(index=index_rows, columns=multi_cols, dtype=float)\n",
    "\n",
    "for met in col_metrics:\n",
    "    report.loc[\"original\", (\"O\", met)] = res_O[met]\n",
    "\n",
    "def put(row, res_F, res_OF):\n",
    "    for met in col_metrics:\n",
    "        report.loc[row, (\"O\", met)]  = res_O[met]\n",
    "        report.loc[row, (\"F\", met)]  = res_F[met]\n",
    "        report.loc[row, (\"OF\", met)] = res_OF[met]\n",
    "\n",
    "put(\"m\",    res_F_m,   res_OF_m)\n",
    "put(\"mw\",   res_F_mw,  res_OF_mw)\n",
    "put(\"m+mw\", res_F_mmw, res_OF_mmw)\n",
    "\n",
    "report = report.astype(float).round(4)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: report_ges_xgboost.csv (format=multi)\n"
     ]
    }
   ],
   "source": [
    "# report: MultiIndex 컬럼의 결과 DataFrame이 이미 존재한다고 가정\n",
    "# format 옵션: \"multi\" | \"flat\" | \"long\"\n",
    "save_format = \"multi\"  # 원하는 포맷으로 변경\n",
    "\n",
    "if save_format == \"multi\":\n",
    "    out_path = \"report_ges_xgboost.csv\"\n",
    "    report.to_csv(out_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "elif save_format == \"flat\":\n",
    "    out_path = \"report_ges_xgboost.csv\"\n",
    "    flat_cols = [f\"{top}_{met}\" for top, met in report.columns.to_list()]\n",
    "    report_flat = report.copy()\n",
    "    report_flat.columns = flat_cols\n",
    "    report_flat.to_csv(out_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "elif save_format == \"long\":\n",
    "    out_path = \"report_ges_xgboost.csv\"\n",
    "    report_long = (\n",
    "        report\n",
    "        .rename_axis(index=\"row\", columns=[\"set\", \"metric\"])\n",
    "        .stack([\"set\", \"metric\"])\n",
    "        .to_frame(\"value\")\n",
    "        .reset_index()[[\"row\", \"set\", \"metric\", \"value\"]]\n",
    "    )\n",
    "    report_long.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "else:\n",
    "    raise ValueError(\"save_format must be one of: 'multi', 'flat', 'long'\")\n",
    "\n",
    "print(f\"Saved: {out_path} (format={save_format})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6630e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] D:\\University\\3-2\\PADALab\\bank_failure_prediction_2\\practice\\Bank_Failure_Prediction_2\\reverse_edge\\confusion_matrix\\ges_xgboost_cm.csv\n"
     ]
    }
   ],
   "source": [
    "# (추가 셀) Confusion Matrix CSV 저장 (GES + XGBoost xgb.train, O/F/OF, m+mw 포함)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, re\n",
    "\n",
    "# ---- 전역 준비물 체크 (위 셀에서 정의됨) ----\n",
    "for v in [\"X_base\", \"Xf_m\", \"Xf_mw\", \"Xf_mmw\", \"y\",\n",
    "          \"N_SPLITS\", \"RANDOM_STATE\",\n",
    "          \"XGB_PARAMS_BASE\", \"NUM_BOOST_ROUND\", \"EARLY_STOPPING\",\n",
    "          \"scale_pos_weight_from_labels\", \"_params_for_train\", \"_predict_booster\"]:\n",
    "    assert v in globals(), f\"'{v}'가 필요합니다. 상단 학습 셀을 먼저 실행하세요.\"\n",
    "\n",
    "# === 저장 파일명 구성 ===\n",
    "DAG_ALGO   = \"ges\"\n",
    "MODEL_NAME = \"xgboost\"\n",
    "\n",
    "def _snake(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = s.replace(\"+\",\" \").replace(\"/\",\" \").replace(\"-\",\" \")\n",
    "    s = re.sub(r\"[^a-z0-9]+\",\"_\", s)\n",
    "    return re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "SAVE_DIR  = Path(\"./confusion_matrix\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_PATH = SAVE_DIR / f\"{_snake(DAG_ALGO)}_{_snake(MODEL_NAME)}_cm.csv\"\n",
    "\n",
    "THRESH = 0.5  # 확률→라벨 변환 임계값\n",
    "\n",
    "def _oof_pred_bin_xgb_train(X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"xgb.train 사용해 OOF 예측 반환 (y_true, y_pred)\"\"\"\n",
    "    X_np = X.values.astype(np.float32)\n",
    "    y_np = y.values.astype(int)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    for tr_idx, te_idx in skf.split(X_np, y_np):\n",
    "        X_tr, X_te = X_np[tr_idx], X_np[te_idx]\n",
    "        y_tr, y_te = y_np[tr_idx], y_np[te_idx]\n",
    "\n",
    "        # 내부 검증(조기 종료)\n",
    "        X_tr_sub, X_val, y_tr_sub, y_val = train_test_split(\n",
    "            X_tr, y_tr, test_size=0.2, random_state=RANDOM_STATE, stratify=y_tr\n",
    "        )\n",
    "\n",
    "        spw = scale_pos_weight_from_labels(y_tr_sub)\n",
    "        params = _params_for_train(XGB_PARAMS_BASE, spw, seed=RANDOM_STATE)\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr_sub, label=y_tr_sub)\n",
    "        dval   = xgb.DMatrix(X_val,    label=y_val)\n",
    "        dtest  = xgb.DMatrix(X_te,     label=y_te)\n",
    "\n",
    "        bst = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=NUM_BOOST_ROUND,\n",
    "            evals=[(dval, \"eval\")],\n",
    "            early_stopping_rounds=EARLY_STOPPING,\n",
    "            maximize=True,        # eval_metric=\"auc\" 최대화\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        proba = _predict_booster(bst, dtest, default_rounds=NUM_BOOST_ROUND)\n",
    "        pred  = (proba >= THRESH).astype(int)\n",
    "\n",
    "        y_true_all.append(y_te)\n",
    "        y_pred_all.append(pred)\n",
    "\n",
    "    return np.concatenate(y_true_all), np.concatenate(y_pred_all)\n",
    "\n",
    "def _cm_dict(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    return {\"TN\": int(cm[0,0]), \"FP\": int(cm[0,1]), \"FN\": int(cm[1,0]), \"TP\": int(cm[1,1])}\n",
    "\n",
    "# ---- 시나리오별 OOF-Confusion Matrix 산출 ----\n",
    "rows = []\n",
    "scenarios = [\n",
    "    (\"original\",\"O\",  X_base),                                      # O: 원피처\n",
    "    (\"m\",\"F\",        Xf_m),                                         # F: 파생만\n",
    "    (\"m\",\"OF\",       pd.concat([X_base, Xf_m],    axis=1)),         # OF: 원+파생\n",
    "    (\"mw\",\"F\",       Xf_mw),\n",
    "    (\"mw\",\"OF\",      pd.concat([X_base, Xf_mw],   axis=1)),\n",
    "]\n",
    "\n",
    "for row_name, set_name, Xmat in scenarios:\n",
    "    yt, yp = _oof_pred_bin_xgb_train(Xmat, y)\n",
    "    d = _cm_dict(yt, yp)\n",
    "    rows.append((row_name, set_name, d[\"TN\"], d[\"FP\"], d[\"FN\"], d[\"TP\"]))\n",
    "\n",
    "cm_table = pd.DataFrame(rows, columns=[\"row\",\"set\",\"TN\",\"FP\",\"FN\",\"TP\"]).set_index([\"row\",\"set\"])\n",
    "\n",
    "# 저장\n",
    "cm_table.to_csv(SAVE_PATH, encoding=\"utf-8-sig\")\n",
    "print(f\"[saved] {SAVE_PATH.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478da9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
